{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Production Forecasting POC (Oil & Gas)\n",
        "\n",
        "This notebook downloads monthly production-by-field data from a configurable internet source (CSV). If not available, it generates a realistic synthetic dataset. It then performs EDA and builds a SARIMAX forecasting model with walk-forward backtesting and plots.\n",
        "\n",
        "Run all cells top-to-bottom.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports and setup\n",
        "import os\n",
        "import io\n",
        "import sys\n",
        "import math\n",
        "import json\n",
        "import time\n",
        "import warnings\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
        "\n",
        "DATA_URL = os.environ.get(\"PROD_DATA_URL\", \"\")  # optional CSV URL\n",
        "DEFAULT_FIELDS = [\"FieldA\", \"FieldB\"]  # used for synthetic fallback\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    target_column: str = \"oil\"\n",
        "    date_column: str = \"date\"\n",
        "    field_column: str = \"field\"\n",
        "    frequency: str = \"MS\"  # month start\n",
        "\n",
        "CFG = Config()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data loading utilities\n",
        "\n",
        "def try_download_csv(url: str, timeout: int = 30) -> Optional[pd.DataFrame]:\n",
        "    if not url:\n",
        "        return None\n",
        "    try:\n",
        "        r = requests.get(url, timeout=timeout)\n",
        "        r.raise_for_status()\n",
        "        df = pd.read_csv(io.StringIO(r.text))\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Download failed from {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def make_synthetic(start=\"2015-01-01\", periods=120, fields=None) -> pd.DataFrame:\n",
        "    if fields is None:\n",
        "        fields = DEFAULT_FIELDS\n",
        "    idx = pd.date_range(start=start, periods=periods, freq=CFG.frequency)\n",
        "    rows = []\n",
        "    rng = np.random.default_rng(42)\n",
        "    for field in fields:\n",
        "        base = rng.uniform(5000, 15000)\n",
        "        decline = rng.uniform(0.002, 0.01)  # monthly decline\n",
        "        season_amp = rng.uniform(0.02, 0.08)\n",
        "        noise_sd = rng.uniform(50, 200)\n",
        "        series = []\n",
        "        for t in range(periods):\n",
        "            seasonal = 1 + season_amp * math.sin(2 * math.pi * t / 12.0)\n",
        "            value = base * ((1 - decline) ** t) * seasonal + rng.normal(0, noise_sd)\n",
        "            series.append(max(value, 0))\n",
        "        for dt, val in zip(idx, series):\n",
        "            rows.append({CFG.date_column: dt, CFG.field_column: field, CFG.target_column: val})\n",
        "    df = pd.DataFrame(rows)\n",
        "    return df\n",
        "\n",
        "\n",
        "def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    cols = {c.lower().strip(): c for c in df.columns}\n",
        "    # try map common variants\n",
        "    mapping = {}\n",
        "    for lc, orig in cols.items():\n",
        "        if lc in {\"date\", \"month\", \"period\"}:\n",
        "            mapping[orig] = CFG.date_column\n",
        "        elif lc in {\"field\", \"asset\", \"area\"}:\n",
        "            mapping[orig] = CFG.field_column\n",
        "        elif lc in {\"oil\", \"oil_bbl\", \"oil_production\", \"production\", \"value\"}:\n",
        "            mapping[orig] = CFG.target_column\n",
        "    df2 = df.rename(columns=mapping)\n",
        "    return df2\n",
        "\n",
        "\n",
        "def coerce_types(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    if CFG.date_column in df.columns:\n",
        "        df[CFG.date_column] = pd.to_datetime(df[CFG.date_column])\n",
        "        df = df.sort_values(CFG.date_column)\n",
        "    if CFG.field_column in df.columns:\n",
        "        df[CFG.field_column] = df[CFG.field_column].astype(str)\n",
        "    if CFG.target_column in df.columns:\n",
        "        df[CFG.target_column] = pd.to_numeric(df[CFG.target_column], errors=\"coerce\")\n",
        "    return df\n",
        "\n",
        "\n",
        "def load_data(data_url: str) -> pd.DataFrame:\n",
        "    df = try_download_csv(data_url)\n",
        "    if df is None:\n",
        "        print(\"Using synthetic fallback dataset.\")\n",
        "        df = make_synthetic()\n",
        "    df = normalize_columns(df)\n",
        "    df = coerce_types(df)\n",
        "    # basic sanity filtering\n",
        "    df = df.dropna(subset=[CFG.date_column, CFG.field_column, CFG.target_column])\n",
        "    return df\n",
        "\n",
        "\n",
        "df_raw = load_data(DATA_URL)\n",
        "df_raw.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EDA\n",
        "print(df_raw.describe(include=\"all\").T.head(10))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,4))\n",
        "for name, g in df_raw.groupby(CFG.field_column):\n",
        "    g = g.sort_values(CFG.date_column)\n",
        "    ax.plot(g[CFG.date_column], g[CFG.target_column], label=name)\n",
        "ax.set_title(\"Monthly production by field\")\n",
        "ax.set_xlabel(\"Date\")\n",
        "ax.set_ylabel(CFG.target_column)\n",
        "ax.legend(loc=\"upper right\")\n",
        "plt.show()\n",
        "\n",
        "# pivot to wide for modeling per field\n",
        "fields = sorted(df_raw[CFG.field_column].unique())\n",
        "print(f\"Fields: {fields}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Walk-forward SARIMAX baseline per field\n",
        "\n",
        "def walk_forward_sarimax(series: pd.Series, order=(1,1,1), seasonal_order=(1,1,1,12), train_ratio=0.8):\n",
        "    series = series.asfreq(CFG.frequency)\n",
        "    n = len(series)\n",
        "    split = int(n * train_ratio)\n",
        "    history = series.iloc[:split]\n",
        "    test = series.iloc[split:]\n",
        "    preds = []\n",
        "    for t in range(len(test)):\n",
        "        model = SARIMAX(history, order=order, seasonal_order=seasonal_order, enforce_stationarity=False, enforce_invertibility=False)\n",
        "        res = model.fit(disp=False)\n",
        "        fc = res.forecast(steps=1)\n",
        "        preds.append(float(fc.iloc[0]))\n",
        "        history = pd.concat([history, test.iloc[t:t+1]])\n",
        "    idx = test.index\n",
        "    y_true = test.values\n",
        "    y_pred = np.array(preds)\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = math.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    return idx, y_true, y_pred, mae, rmse\n",
        "\n",
        "metrics = []\n",
        "plots = []\n",
        "for field in fields:\n",
        "    s = (df_raw[df_raw[CFG.field_column]==field]\n",
        "            .set_index(CFG.date_column)[CFG.target_column]\n",
        "            .asfreq(CFG.frequency)\n",
        "            .interpolate(limit_direction=\"both\"))\n",
        "    idx, y_true, y_pred, mae, rmse = walk_forward_sarimax(s)\n",
        "    metrics.append({\"field\": field, \"mae\": mae, \"rmse\": rmse})\n",
        "    # Plot\n",
        "    fig, ax = plt.subplots(figsize=(10,4))\n",
        "    ax.plot(s.index, s.values, label=\"actual\", alpha=0.6)\n",
        "    ax.plot(idx, y_pred, label=\"pred (walk-forward)\")\n",
        "    ax.set_title(f\"Forecast vs Actual - {field}\")\n",
        "    ax.set_xlabel(\"Date\")\n",
        "    ax.set_ylabel(CFG.target_column)\n",
        "    ax.legend()\n",
        "    plt.show()\n",
        "\n",
        "pd.DataFrame(metrics).sort_values(\"rmse\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple explainability: recent change features and correlations\n",
        "\n",
        "df_features = []\n",
        "for field in fields:\n",
        "    g = df_raw[df_raw[CFG.field_column]==field].sort_values(CFG.date_column).copy()\n",
        "    g[\"lag1\"] = g[CFG.target_column].shift(1)\n",
        "    g[\"chg1\"] = g[CFG.target_column].diff(1)\n",
        "    g[\"ma3\"] = g[CFG.target_column].rolling(3).mean()\n",
        "    g[\"ma6\"] = g[CFG.target_column].rolling(6).mean()\n",
        "    g[\"y\"] = g[CFG.target_column]\n",
        "    g[\"field\"] = field\n",
        "    df_features.append(g)\n",
        "X = pd.concat(df_features, ignore_index=True).dropna()\n",
        "\n",
        "corr = X[[\"y\",\"lag1\",\"chg1\",\"ma3\",\"ma6\"]].corr()\n",
        "print(corr)\n",
        "\n",
        "sns.pairplot(X[[\"y\",\"lag1\",\"chg1\",\"ma3\",\"ma6\"]].sample(min(2000, len(X))), corner=True)\n",
        "plt.suptitle(\"Feature relationships\", y=1.02)\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
